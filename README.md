# Agente IA en local para la gestiÃ³n de horas mÃ©dicas

Este proyecto implementa un agente de inteligencia artificial capaz de interactuar en lenguaje natural con los usuarios para gestionar citas mÃ©dicas. Se ejecuta de manera local utilizando modelos LLM con Ollama, y estÃ¡ integrado con una base de datos MySQL y un bot de Telegram.

> âš ï¸ Proyecto con fines exclusivamente educativos.

## ğŸ›  Herramientas utilizadas

- **[Ollama 0.9.2](https://ollama.com)**
- **Python 3.13.0**
- **MySQL 8.0.42**
- **Telegram Bot API**

## ğŸ“‚ Estructura del proyecto

- `main.py`: Ejecuta el agente conectado con el bot de Telegram.
- `agent.py`: Contiene la lÃ³gica principal del agente (casos de uso, flujo conversacional).
- `api.py`: Maneja la lÃ³gica de conexiÃ³n y consultas a la base de datos.
- `db.sql`: Script de creaciÃ³n de la base de datos y carga de datos de prueba.
- `requirements.txt`: Lista de dependencias necesarias para ejecutar el proyecto.

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio:**

```bash
git clone https://github.com/mark3tmaker/agenteIA
cd agenteIA
```

2. **Instalar dependencias:**

```bash
pip install -r requirements.txt
```

3. **Instalar y ejecutar Ollama:**

```bash
ollama serve
ollama pull gemma3
ollama run gemma3
```

Verifica que la API de Ollama funcione accediendo a:

```
http://127.0.0.1:11434
```

DeberÃ­as ver: `Ollama is running`.

4. **Cargar la base de datos MySQL:**

```bash
mysql -u tu_usuario -p tu_basededatos < db.sql
```

5. **Configurar conexiÃ³n a la base de datos en `api.py`:**

```python
# ConfiguraciÃ³n de la base de datos
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'tu_usuario'
app.config['MYSQL_PASSWORD'] = 'tu_password'
app.config['MYSQL_DB'] = 'nombre_base_de_datos'
```

6. **Crear un bot de Telegram:**

Sigue este [tutorial para crear tu bot](https://core.telegram.org/bots/tutorial). Guarda tu token y chat ID.

En `main.py`, agrega:

```python
telegram_token = 'TOKEN_DEL_BOT'
chat_id = 'CHAT_ID_PRIVADO'
```

## ğŸ’¬ Casos de uso implementados

| Caso de Uso | DescripciÃ³n                                                |
|-------------|------------------------------------------------------------|
| CU 0        | Determina la intenciÃ³n del usuario (agendar, consultar, borrar). |
| CU 1        | Solicita doctor para agendar una cita.                     |
| CU 1.1      | Muestra disponibilidad del doctor.                         |
| CU 1.2      | Solicita RUT y agenda en base de datos.                    |
| CU 2        | Consulta citas segÃºn el RUT.                               |
| CU 2.1      | Informa al paciente sus citas agendadas.                   |
| CU 3        | Solicita RUT para anular cita mÃ©dica.                      |
| CU 3.1      | Solicita fecha, hora y doctor para anular cita.           |
| CU 4        | Pregunta si desea realizar otra acciÃ³n.                    |

> El caso de uso **Modificar** se interpreta como una combinaciÃ³n de agendar una nueva cita y eliminar la anterior.

## ğŸ§  ExtracciÃ³n de parÃ¡metros con salidas estructuradas

Este proyecto utiliza **salidas estructuradas de Ollama** para extraer parÃ¡metros como el RUT desde el historial de mensajes del usuario. Por ejemplo:

```python
prompt = "Considera los siguientes mensajes: {messages}. En base a estos, responde en formato JSON con el RUT del paciente."
```

El modelo responde:

```json
{"rut": "123456789"}
```

## ğŸ“Š Base de datos

El modelo relacional incluye las siguientes tablas:

- **mÃ©dicos**
- **pacientes**
- **agenda**

Consulta y actualizaciÃ³n se realizan vÃ­a endpoints API como `/disponibilidad`, `/agendar`, `/consultarcitas`, `/borrarcita`.

## ğŸ¤– Funcionamiento general

El agente conversa con el usuario en Telegram, interpreta su intenciÃ³n, extrae los parÃ¡metros necesarios mediante un prompt de razonamiento y consulta la base de datos o realiza modificaciones segÃºn corresponda.

## ğŸ§ª Pruebas y flujo

- Agendar: CU 0 â†’ CU 1 â†’ CU 1.1 â†’ CU 1.2 â†’ CU 4
- Consultar: CU 0 â†’ CU 2 â†’ CU 2.1 â†’ CU 4
- Borrar: CU 0 â†’ CU 3 â†’ CU 3.1 â†’ CU 4

## ğŸ§­ Comentarios finales

Implementar LLMs en local ofrece ventajas como privacidad, control total del servicio y ahorro en costos a largo plazo. Aunque la inversiÃ³n en hardware puede ser alta, este enfoque permite independencia de servicios externos y experimentaciÃ³n libre.

El uso de **cadenas de razonamiento** y salidas estructuradas hace posible construir agentes conversacionales funcionales sin depender de APIs de pago.

## ğŸ“˜ Referencias

- [Ollama Structured Outputs](https://ollama.com/blog/structured-outputs)
- [Telegram Bot API](https://core.telegram.org/bots/api)
- [Model Context Protocol (MCP)](https://github.com/modelcontext/protocol)

---

**Autor:** [@mark3tmaker](https://github.com/mark3tmaker)  
ğŸ“… Proyecto iniciado en

